{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/Control-RL/Function-Approximation --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import Categorical\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99\n",
    "\n",
    "class Pi(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Pi, self).__init__()\n",
    "        layers = [\n",
    "            nn.Linear(in_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, out_dim),\n",
    "        ]\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.onpolicy_reset()\n",
    "        self.train()  # set training mode\n",
    "\n",
    "    def onpolicy_reset(self):\n",
    "        self.log_probs = []\n",
    "        self.rewards = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        pdparam = self.model(x)\n",
    "        return pdparam\n",
    "\n",
    "    def act(self, state):\n",
    "        x = torch.from_numpy(state.astype(np.float32))  # to tensor\n",
    "        pdparam = self.forward(x)  # forward pass\n",
    "        pd = torch.distributions.Categorical(logits=pdparam)  # probability distribution\n",
    "        action = pd.sample()  # pi(a|s) in action via pd\n",
    "        log_prob = pd.log_prob(action)  # log prob of pi(a|s)\n",
    "        self.log_probs.append(log_prob)  # store for training\n",
    "        return action.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inner gradient loop of basic policy-gradient algorithm (Reinforce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(pi, optimizer):\n",
    "    # Inner gradient-ascent loop of REINFORCE algorithm\n",
    "    T = len(pi.rewards)\n",
    "    rets = np.empty(T, dtype=np.float32)  # the returns\n",
    "    future_ret = 0.0\n",
    "    # compute the returns efficiently\n",
    "    for t in reversed(range(T)):\n",
    "        future_ret = pi.rewards[t] + gamma * future_ret\n",
    "        rets[t] = future_ret\n",
    "\n",
    "    # Compute returns\n",
    "    rets = torch.tensor(rets)\n",
    "    log_probs = torch.stack(pi.log_probs)\n",
    "    \n",
    "    # Compute loss (REINFORCE gradient term)\n",
    "    loss = -log_probs * rets  # Negative for maximizing\n",
    "    loss = torch.sum(loss)\n",
    "\n",
    "    # Perform gradient ascent\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()  # Backpropagate, compute gradients\n",
    "    optimizer.step()  # Gradient-ascent, update the weights\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, loss: 509.3688659667969, total_reward: 40.0, solved: False\n",
      "Episode 1, loss: 59.98950958251953, total_reward: 13.0, solved: False\n",
      "Episode 2, loss: 163.4646453857422, total_reward: 22.0, solved: False\n",
      "Episode 3, loss: 308.8516845703125, total_reward: 31.0, solved: False\n",
      "Episode 4, loss: 1752.55029296875, total_reward: 81.0, solved: False\n",
      "Episode 5, loss: 1046.2186279296875, total_reward: 61.0, solved: False\n",
      "Episode 6, loss: 777.6467895507812, total_reward: 52.0, solved: False\n",
      "Episode 7, loss: 234.26364135742188, total_reward: 27.0, solved: False\n",
      "Episode 8, loss: 146.66159057617188, total_reward: 21.0, solved: False\n",
      "Episode 9, loss: 411.069580078125, total_reward: 37.0, solved: False\n",
      "Episode 10, loss: 1688.4718017578125, total_reward: 82.0, solved: False\n",
      "Episode 11, loss: 762.0066528320312, total_reward: 51.0, solved: False\n",
      "Episode 12, loss: 266.7779235839844, total_reward: 30.0, solved: False\n",
      "Episode 13, loss: 875.4495849609375, total_reward: 58.0, solved: False\n",
      "Episode 14, loss: 693.7012939453125, total_reward: 49.0, solved: False\n",
      "Episode 15, loss: 471.74200439453125, total_reward: 41.0, solved: False\n",
      "Episode 16, loss: 1548.478271484375, total_reward: 80.0, solved: False\n",
      "Episode 17, loss: 497.82159423828125, total_reward: 42.0, solved: False\n",
      "Episode 18, loss: 223.66183471679688, total_reward: 27.0, solved: False\n",
      "Episode 19, loss: 686.3373413085938, total_reward: 50.0, solved: False\n",
      "Episode 20, loss: 719.4236450195312, total_reward: 53.0, solved: False\n",
      "Episode 21, loss: 1059.599609375, total_reward: 64.0, solved: False\n",
      "Episode 22, loss: 2013.1204833984375, total_reward: 93.0, solved: False\n",
      "Episode 23, loss: 1239.5286865234375, total_reward: 71.0, solved: False\n",
      "Episode 24, loss: 975.47607421875, total_reward: 62.0, solved: False\n",
      "Episode 25, loss: 451.8164367675781, total_reward: 43.0, solved: False\n",
      "Episode 26, loss: 226.21966552734375, total_reward: 28.0, solved: False\n",
      "Episode 27, loss: 1468.494384765625, total_reward: 80.0, solved: False\n",
      "Episode 28, loss: 254.86715698242188, total_reward: 30.0, solved: False\n",
      "Episode 29, loss: 2070.987060546875, total_reward: 96.0, solved: False\n",
      "Episode 30, loss: 474.3667297363281, total_reward: 42.0, solved: False\n",
      "Episode 31, loss: 848.8587646484375, total_reward: 60.0, solved: False\n",
      "Episode 32, loss: 2947.239990234375, total_reward: 119.0, solved: False\n",
      "Episode 33, loss: 1386.6741943359375, total_reward: 78.0, solved: False\n",
      "Episode 34, loss: 1776.996826171875, total_reward: 90.0, solved: False\n",
      "Episode 35, loss: 791.9578247070312, total_reward: 55.0, solved: False\n",
      "Episode 36, loss: 2350.916259765625, total_reward: 101.0, solved: False\n",
      "Episode 37, loss: 574.4810180664062, total_reward: 49.0, solved: False\n",
      "Episode 38, loss: 989.4304809570312, total_reward: 64.0, solved: False\n",
      "Episode 39, loss: 1335.725830078125, total_reward: 78.0, solved: False\n",
      "Episode 40, loss: 1647.0933837890625, total_reward: 86.0, solved: False\n",
      "Episode 41, loss: 2679.2548828125, total_reward: 118.0, solved: False\n",
      "Episode 42, loss: 951.772216796875, total_reward: 62.0, solved: False\n",
      "Episode 43, loss: 606.216796875, total_reward: 50.0, solved: False\n",
      "Episode 44, loss: 2052.621826171875, total_reward: 99.0, solved: False\n",
      "Episode 45, loss: 904.483642578125, total_reward: 60.0, solved: False\n",
      "Episode 46, loss: 916.3167114257812, total_reward: 64.0, solved: False\n",
      "Episode 47, loss: 2628.370849609375, total_reward: 119.0, solved: False\n",
      "Episode 48, loss: 517.1992797851562, total_reward: 45.0, solved: False\n",
      "Episode 49, loss: 1834.1292724609375, total_reward: 90.0, solved: False\n",
      "Episode 50, loss: 1418.148681640625, total_reward: 82.0, solved: False\n",
      "Episode 51, loss: 1156.673095703125, total_reward: 73.0, solved: False\n",
      "Episode 52, loss: 2502.929443359375, total_reward: 113.0, solved: False\n",
      "Episode 53, loss: 713.3130493164062, total_reward: 55.0, solved: False\n",
      "Episode 54, loss: 1381.04443359375, total_reward: 85.0, solved: False\n",
      "Episode 55, loss: 2021.7227783203125, total_reward: 98.0, solved: False\n",
      "Episode 56, loss: 769.234375, total_reward: 60.0, solved: False\n",
      "Episode 57, loss: 1301.5015869140625, total_reward: 80.0, solved: False\n",
      "Episode 58, loss: 1957.537353515625, total_reward: 96.0, solved: False\n",
      "Episode 59, loss: 866.782958984375, total_reward: 59.0, solved: False\n",
      "Episode 60, loss: 408.9441833496094, total_reward: 39.0, solved: False\n",
      "Episode 61, loss: 1502.280029296875, total_reward: 86.0, solved: False\n",
      "Episode 62, loss: 184.72415161132812, total_reward: 24.0, solved: False\n",
      "Episode 63, loss: 759.999267578125, total_reward: 60.0, solved: False\n",
      "Episode 64, loss: 2301.842041015625, total_reward: 109.0, solved: False\n",
      "Episode 65, loss: 991.1883544921875, total_reward: 66.0, solved: False\n",
      "Episode 66, loss: 2910.757080078125, total_reward: 124.0, solved: False\n",
      "Episode 67, loss: 3640.194091796875, total_reward: 137.0, solved: False\n",
      "Episode 68, loss: 1104.8515625, total_reward: 72.0, solved: False\n",
      "Episode 69, loss: 2610.35791015625, total_reward: 120.0, solved: False\n",
      "Episode 70, loss: 6284.302734375, total_reward: 200.0, solved: True\n",
      "Episode 71, loss: 3043.548828125, total_reward: 121.0, solved: False\n",
      "Episode 72, loss: 3485.90771484375, total_reward: 132.0, solved: False\n",
      "Episode 73, loss: 3941.0888671875, total_reward: 148.0, solved: False\n",
      "Episode 74, loss: 6120.94921875, total_reward: 200.0, solved: True\n",
      "Episode 75, loss: 4586.91015625, total_reward: 155.0, solved: False\n",
      "Episode 76, loss: 805.283203125, total_reward: 57.0, solved: False\n",
      "Episode 77, loss: 2237.724609375, total_reward: 102.0, solved: False\n",
      "Episode 78, loss: 6239.900390625, total_reward: 200.0, solved: True\n",
      "Episode 79, loss: 3743.1923828125, total_reward: 144.0, solved: False\n",
      "Episode 80, loss: 5090.30224609375, total_reward: 173.0, solved: False\n",
      "Episode 81, loss: 6286.62646484375, total_reward: 200.0, solved: True\n",
      "Episode 82, loss: 4192.15234375, total_reward: 152.0, solved: False\n",
      "Episode 83, loss: 4111.87890625, total_reward: 157.0, solved: False\n",
      "Episode 84, loss: 3305.563232421875, total_reward: 135.0, solved: False\n",
      "Episode 85, loss: 6148.00048828125, total_reward: 200.0, solved: True\n",
      "Episode 86, loss: 3247.007568359375, total_reward: 135.0, solved: False\n",
      "Episode 87, loss: 2367.934814453125, total_reward: 108.0, solved: False\n",
      "Episode 88, loss: 1865.3770751953125, total_reward: 95.0, solved: False\n",
      "Episode 89, loss: 4299.3857421875, total_reward: 161.0, solved: False\n",
      "Episode 90, loss: 6138.8427734375, total_reward: 200.0, solved: True\n",
      "Episode 91, loss: 2776.4130859375, total_reward: 120.0, solved: False\n",
      "Episode 92, loss: 6607.328125, total_reward: 200.0, solved: True\n",
      "Episode 93, loss: 3009.310791015625, total_reward: 125.0, solved: False\n",
      "Episode 94, loss: 3835.82763671875, total_reward: 149.0, solved: False\n",
      "Episode 95, loss: 5313.7607421875, total_reward: 181.0, solved: False\n",
      "Episode 96, loss: 6271.23486328125, total_reward: 200.0, solved: True\n",
      "Episode 97, loss: 4344.642578125, total_reward: 157.0, solved: False\n",
      "Episode 98, loss: 1430.6622314453125, total_reward: 82.0, solved: False\n",
      "Episode 99, loss: 1791.31591796875, total_reward: 89.0, solved: False\n",
      "Episode 100, loss: 6059.9970703125, total_reward: 200.0, solved: True\n",
      "Episode 101, loss: 2230.5537109375, total_reward: 100.0, solved: False\n",
      "Episode 102, loss: 5334.81103515625, total_reward: 175.0, solved: False\n",
      "Episode 103, loss: 2872.87109375, total_reward: 118.0, solved: False\n",
      "Episode 104, loss: 5539.73095703125, total_reward: 181.0, solved: False\n",
      "Episode 105, loss: 2653.912109375, total_reward: 113.0, solved: False\n",
      "Episode 106, loss: 6242.615234375, total_reward: 200.0, solved: True\n",
      "Episode 107, loss: 6752.95361328125, total_reward: 200.0, solved: True\n",
      "Episode 108, loss: 4341.34375, total_reward: 156.0, solved: False\n",
      "Episode 109, loss: 6221.0712890625, total_reward: 200.0, solved: True\n",
      "Episode 110, loss: 6495.50048828125, total_reward: 200.0, solved: True\n",
      "Episode 111, loss: 3760.685791015625, total_reward: 143.0, solved: False\n",
      "Episode 112, loss: 1278.9058837890625, total_reward: 72.0, solved: False\n",
      "Episode 113, loss: 6203.5859375, total_reward: 200.0, solved: True\n",
      "Episode 114, loss: 5616.13330078125, total_reward: 186.0, solved: False\n",
      "Episode 115, loss: 1239.1014404296875, total_reward: 74.0, solved: False\n",
      "Episode 116, loss: 1145.97802734375, total_reward: 72.0, solved: False\n",
      "Episode 117, loss: 6353.40283203125, total_reward: 200.0, solved: True\n",
      "Episode 118, loss: 4965.18017578125, total_reward: 167.0, solved: False\n",
      "Episode 119, loss: 1924.866455078125, total_reward: 99.0, solved: False\n",
      "Episode 120, loss: 6371.54296875, total_reward: 200.0, solved: True\n",
      "Episode 121, loss: 5979.23193359375, total_reward: 200.0, solved: True\n",
      "Episode 122, loss: 3220.735595703125, total_reward: 134.0, solved: False\n",
      "Episode 123, loss: 1945.287841796875, total_reward: 94.0, solved: False\n",
      "Episode 124, loss: 5986.9296875, total_reward: 200.0, solved: True\n",
      "Episode 125, loss: 6229.7431640625, total_reward: 200.0, solved: True\n",
      "Episode 126, loss: 6369.9296875, total_reward: 200.0, solved: True\n",
      "Episode 127, loss: 6241.76171875, total_reward: 200.0, solved: True\n",
      "Episode 128, loss: 5876.134765625, total_reward: 200.0, solved: True\n",
      "Episode 129, loss: 2236.639404296875, total_reward: 101.0, solved: False\n",
      "Episode 130, loss: 5740.408203125, total_reward: 200.0, solved: True\n",
      "Episode 131, loss: 5424.5966796875, total_reward: 187.0, solved: False\n",
      "Episode 132, loss: 5828.3779296875, total_reward: 200.0, solved: True\n",
      "Episode 133, loss: 6363.8564453125, total_reward: 200.0, solved: True\n",
      "Episode 134, loss: 6000.47607421875, total_reward: 200.0, solved: True\n",
      "Episode 135, loss: 5251.02099609375, total_reward: 193.0, solved: False\n",
      "Episode 136, loss: 6127.6728515625, total_reward: 200.0, solved: True\n",
      "Episode 137, loss: 5630.48291015625, total_reward: 200.0, solved: True\n",
      "Episode 138, loss: 5610.84912109375, total_reward: 198.0, solved: True\n",
      "Episode 139, loss: 5728.8837890625, total_reward: 200.0, solved: True\n",
      "Episode 140, loss: 4937.39404296875, total_reward: 189.0, solved: False\n",
      "Episode 141, loss: 6002.07763671875, total_reward: 200.0, solved: True\n",
      "Episode 142, loss: 5708.2412109375, total_reward: 200.0, solved: True\n",
      "Episode 143, loss: 5495.001953125, total_reward: 200.0, solved: True\n",
      "Episode 144, loss: 5229.78955078125, total_reward: 200.0, solved: True\n",
      "Episode 145, loss: 5196.681640625, total_reward: 190.0, solved: False\n",
      "Episode 146, loss: 4587.42333984375, total_reward: 178.0, solved: False\n",
      "Episode 147, loss: 4583.8369140625, total_reward: 200.0, solved: True\n",
      "Episode 148, loss: 4739.84912109375, total_reward: 200.0, solved: True\n",
      "Episode 149, loss: 4317.96728515625, total_reward: 192.0, solved: False\n",
      "Episode 150, loss: 5424.8017578125, total_reward: 200.0, solved: True\n",
      "Episode 151, loss: 5032.21142578125, total_reward: 200.0, solved: True\n",
      "Episode 152, loss: 4663.5458984375, total_reward: 200.0, solved: True\n",
      "Episode 153, loss: 5040.0849609375, total_reward: 200.0, solved: True\n",
      "Episode 154, loss: 4455.3359375, total_reward: 200.0, solved: True\n",
      "Episode 155, loss: 4611.5595703125, total_reward: 200.0, solved: True\n",
      "Episode 156, loss: 4534.9990234375, total_reward: 200.0, solved: True\n",
      "Episode 157, loss: 4233.595703125, total_reward: 200.0, solved: True\n",
      "Episode 158, loss: 4665.44091796875, total_reward: 200.0, solved: True\n",
      "Episode 159, loss: 4576.15869140625, total_reward: 200.0, solved: True\n",
      "Episode 160, loss: 4318.65380859375, total_reward: 200.0, solved: True\n",
      "Episode 161, loss: 5042.4208984375, total_reward: 200.0, solved: True\n",
      "Episode 162, loss: 4056.86328125, total_reward: 200.0, solved: True\n",
      "Episode 163, loss: 4055.9921875, total_reward: 182.0, solved: False\n",
      "Episode 164, loss: 3986.0869140625, total_reward: 200.0, solved: True\n",
      "Episode 165, loss: 3742.153076171875, total_reward: 200.0, solved: True\n",
      "Episode 166, loss: 2856.066162109375, total_reward: 159.0, solved: False\n",
      "Episode 167, loss: 4631.13330078125, total_reward: 200.0, solved: True\n",
      "Episode 168, loss: 4272.5068359375, total_reward: 200.0, solved: True\n",
      "Episode 169, loss: 3853.963623046875, total_reward: 200.0, solved: True\n",
      "Episode 170, loss: 3557.222900390625, total_reward: 172.0, solved: False\n",
      "Episode 171, loss: 3605.319091796875, total_reward: 200.0, solved: True\n",
      "Episode 172, loss: 4424.0, total_reward: 200.0, solved: True\n",
      "Episode 173, loss: 4654.09814453125, total_reward: 200.0, solved: True\n",
      "Episode 174, loss: 4137.0849609375, total_reward: 200.0, solved: True\n",
      "Episode 175, loss: 4220.8896484375, total_reward: 200.0, solved: True\n",
      "Episode 176, loss: 4134.2978515625, total_reward: 200.0, solved: True\n",
      "Episode 177, loss: 4318.91650390625, total_reward: 200.0, solved: True\n",
      "Episode 178, loss: 4388.30078125, total_reward: 200.0, solved: True\n",
      "Episode 179, loss: 3171.5947265625, total_reward: 200.0, solved: True\n",
      "Episode 180, loss: 3636.1796875, total_reward: 200.0, solved: True\n",
      "Episode 181, loss: 4412.12646484375, total_reward: 200.0, solved: True\n",
      "Episode 182, loss: 3658.564208984375, total_reward: 192.0, solved: False\n",
      "Episode 183, loss: 4195.8681640625, total_reward: 200.0, solved: True\n",
      "Episode 184, loss: 4085.513427734375, total_reward: 200.0, solved: True\n",
      "Episode 185, loss: 4285.6396484375, total_reward: 200.0, solved: True\n",
      "Episode 186, loss: 3548.34228515625, total_reward: 200.0, solved: True\n",
      "Episode 187, loss: 2765.481201171875, total_reward: 200.0, solved: True\n",
      "Episode 188, loss: 4079.6611328125, total_reward: 200.0, solved: True\n",
      "Episode 189, loss: 3843.836669921875, total_reward: 197.0, solved: True\n",
      "Episode 190, loss: 4017.869140625, total_reward: 200.0, solved: True\n",
      "Episode 191, loss: 3655.2412109375, total_reward: 200.0, solved: True\n",
      "Episode 192, loss: 3681.68017578125, total_reward: 200.0, solved: True\n",
      "Episode 193, loss: 3878.393310546875, total_reward: 200.0, solved: True\n",
      "Episode 194, loss: 3689.79443359375, total_reward: 200.0, solved: True\n",
      "Episode 195, loss: 4020.34619140625, total_reward: 200.0, solved: True\n",
      "Episode 196, loss: 3590.821533203125, total_reward: 200.0, solved: True\n",
      "Episode 197, loss: 3407.31689453125, total_reward: 200.0, solved: True\n",
      "Episode 198, loss: 3514.69189453125, total_reward: 200.0, solved: True\n",
      "Episode 199, loss: 4265.572265625, total_reward: 200.0, solved: True\n",
      "Episode 200, loss: 4215.71484375, total_reward: 200.0, solved: True\n",
      "Episode 201, loss: 3753.734375, total_reward: 200.0, solved: True\n",
      "Episode 202, loss: 3908.248779296875, total_reward: 200.0, solved: True\n",
      "Episode 203, loss: 3889.900390625, total_reward: 200.0, solved: True\n",
      "Episode 204, loss: 4224.15283203125, total_reward: 200.0, solved: True\n",
      "Episode 205, loss: 3358.629150390625, total_reward: 200.0, solved: True\n",
      "Episode 206, loss: 4134.6328125, total_reward: 200.0, solved: True\n",
      "Episode 207, loss: 4711.2880859375, total_reward: 200.0, solved: True\n",
      "Episode 208, loss: 3962.0576171875, total_reward: 200.0, solved: True\n",
      "Episode 209, loss: 4204.60400390625, total_reward: 200.0, solved: True\n",
      "Episode 210, loss: 4042.85009765625, total_reward: 200.0, solved: True\n",
      "Episode 211, loss: 3635.92529296875, total_reward: 200.0, solved: True\n",
      "Episode 212, loss: 4705.23583984375, total_reward: 200.0, solved: True\n",
      "Episode 213, loss: 4171.19921875, total_reward: 200.0, solved: True\n",
      "Episode 214, loss: 3209.498046875, total_reward: 161.0, solved: False\n",
      "Episode 215, loss: 4681.24560546875, total_reward: 200.0, solved: True\n",
      "Episode 216, loss: 2832.236083984375, total_reward: 177.0, solved: False\n",
      "Episode 217, loss: 3790.13623046875, total_reward: 200.0, solved: True\n",
      "Episode 218, loss: 3805.409912109375, total_reward: 170.0, solved: False\n",
      "Episode 219, loss: 2856.93115234375, total_reward: 147.0, solved: False\n",
      "Episode 220, loss: 2609.7109375, total_reward: 150.0, solved: False\n",
      "Episode 221, loss: 2105.269775390625, total_reward: 142.0, solved: False\n",
      "Episode 222, loss: 2438.076904296875, total_reward: 135.0, solved: False\n",
      "Episode 223, loss: 2473.933837890625, total_reward: 139.0, solved: False\n",
      "Episode 224, loss: 1970.7781982421875, total_reward: 126.0, solved: False\n",
      "Episode 225, loss: 1790.2286376953125, total_reward: 118.0, solved: False\n",
      "Episode 226, loss: 1723.015380859375, total_reward: 119.0, solved: False\n",
      "Episode 227, loss: 1825.537353515625, total_reward: 125.0, solved: False\n",
      "Episode 228, loss: 2014.4927978515625, total_reward: 119.0, solved: False\n",
      "Episode 229, loss: 1168.882568359375, total_reward: 103.0, solved: False\n",
      "Episode 230, loss: 1087.598388671875, total_reward: 88.0, solved: False\n",
      "Episode 231, loss: 1462.741943359375, total_reward: 115.0, solved: False\n",
      "Episode 232, loss: 1222.5496826171875, total_reward: 90.0, solved: False\n",
      "Episode 233, loss: 736.2373657226562, total_reward: 74.0, solved: False\n",
      "Episode 234, loss: 659.5258178710938, total_reward: 76.0, solved: False\n",
      "Episode 235, loss: 683.375244140625, total_reward: 69.0, solved: False\n",
      "Episode 236, loss: 839.8242797851562, total_reward: 63.0, solved: False\n",
      "Episode 237, loss: 691.9252319335938, total_reward: 68.0, solved: False\n",
      "Episode 238, loss: 412.3334045410156, total_reward: 64.0, solved: False\n",
      "Episode 239, loss: 598.5853271484375, total_reward: 60.0, solved: False\n",
      "Episode 240, loss: 1120.58203125, total_reward: 90.0, solved: False\n",
      "Episode 241, loss: 462.0307312011719, total_reward: 58.0, solved: False\n",
      "Episode 242, loss: 831.1597290039062, total_reward: 73.0, solved: False\n",
      "Episode 243, loss: 881.0656127929688, total_reward: 74.0, solved: False\n",
      "Episode 244, loss: 692.752197265625, total_reward: 66.0, solved: False\n",
      "Episode 245, loss: 622.4463500976562, total_reward: 65.0, solved: False\n",
      "Episode 246, loss: 588.1151123046875, total_reward: 71.0, solved: False\n",
      "Episode 247, loss: 792.354736328125, total_reward: 71.0, solved: False\n",
      "Episode 248, loss: 703.84716796875, total_reward: 66.0, solved: False\n",
      "Episode 249, loss: 810.7399291992188, total_reward: 75.0, solved: False\n",
      "Episode 250, loss: 308.7151184082031, total_reward: 47.0, solved: False\n",
      "Episode 251, loss: 464.51019287109375, total_reward: 64.0, solved: False\n",
      "Episode 252, loss: 479.21148681640625, total_reward: 55.0, solved: False\n",
      "Episode 253, loss: 634.7481079101562, total_reward: 61.0, solved: False\n",
      "Episode 254, loss: 500.6475830078125, total_reward: 64.0, solved: False\n",
      "Episode 255, loss: 721.1360473632812, total_reward: 82.0, solved: False\n",
      "Episode 256, loss: 427.10528564453125, total_reward: 52.0, solved: False\n",
      "Episode 257, loss: 554.5860595703125, total_reward: 65.0, solved: False\n",
      "Episode 258, loss: 759.0859985351562, total_reward: 69.0, solved: False\n",
      "Episode 259, loss: 798.9544677734375, total_reward: 71.0, solved: False\n",
      "Episode 260, loss: 795.32177734375, total_reward: 77.0, solved: False\n",
      "Episode 261, loss: 465.0724182128906, total_reward: 66.0, solved: False\n",
      "Episode 262, loss: 475.8399353027344, total_reward: 59.0, solved: False\n",
      "Episode 263, loss: 578.7492065429688, total_reward: 73.0, solved: False\n",
      "Episode 264, loss: 1087.5361328125, total_reward: 92.0, solved: False\n",
      "Episode 265, loss: 779.9898681640625, total_reward: 72.0, solved: False\n",
      "Episode 266, loss: 767.0531005859375, total_reward: 80.0, solved: False\n",
      "Episode 267, loss: 1056.50390625, total_reward: 96.0, solved: False\n",
      "Episode 268, loss: 749.2069091796875, total_reward: 75.0, solved: False\n",
      "Episode 269, loss: 694.1265869140625, total_reward: 82.0, solved: False\n",
      "Episode 270, loss: 836.5054321289062, total_reward: 75.0, solved: False\n",
      "Episode 271, loss: 1358.4283447265625, total_reward: 91.0, solved: False\n",
      "Episode 272, loss: 621.9679565429688, total_reward: 61.0, solved: False\n",
      "Episode 273, loss: 773.9095458984375, total_reward: 78.0, solved: False\n",
      "Episode 274, loss: 1292.433349609375, total_reward: 106.0, solved: False\n",
      "Episode 275, loss: 1209.1810302734375, total_reward: 96.0, solved: False\n",
      "Episode 276, loss: 1559.3863525390625, total_reward: 108.0, solved: False\n",
      "Episode 277, loss: 1827.254638671875, total_reward: 122.0, solved: False\n",
      "Episode 278, loss: 1204.03662109375, total_reward: 108.0, solved: False\n",
      "Episode 279, loss: 2216.750732421875, total_reward: 132.0, solved: False\n",
      "Episode 280, loss: 2243.019775390625, total_reward: 141.0, solved: False\n",
      "Episode 281, loss: 2126.48095703125, total_reward: 123.0, solved: False\n",
      "Episode 282, loss: 3120.110107421875, total_reward: 171.0, solved: False\n",
      "Episode 283, loss: 2194.4677734375, total_reward: 140.0, solved: False\n",
      "Episode 284, loss: 3017.149169921875, total_reward: 157.0, solved: False\n",
      "Episode 285, loss: 2882.08349609375, total_reward: 182.0, solved: False\n",
      "Episode 286, loss: 3590.3115234375, total_reward: 200.0, solved: True\n",
      "Episode 287, loss: 4079.456787109375, total_reward: 197.0, solved: True\n",
      "Episode 288, loss: 4249.40869140625, total_reward: 200.0, solved: True\n",
      "Episode 289, loss: 4281.57080078125, total_reward: 200.0, solved: True\n",
      "Episode 290, loss: 3889.91796875, total_reward: 200.0, solved: True\n",
      "Episode 291, loss: 3541.7373046875, total_reward: 200.0, solved: True\n",
      "Episode 292, loss: 4302.423828125, total_reward: 200.0, solved: True\n",
      "Episode 293, loss: 4571.9794921875, total_reward: 200.0, solved: True\n",
      "Episode 294, loss: 3918.482421875, total_reward: 200.0, solved: True\n",
      "Episode 295, loss: 4423.0830078125, total_reward: 200.0, solved: True\n",
      "Episode 296, loss: 3664.062744140625, total_reward: 200.0, solved: True\n",
      "Episode 297, loss: 3976.15673828125, total_reward: 200.0, solved: True\n",
      "Episode 298, loss: 3870.5400390625, total_reward: 200.0, solved: True\n",
      "Episode 299, loss: 4223.72119140625, total_reward: 200.0, solved: True\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "in_dim = env.observation_space.shape[0]  # 4\n",
    "out_dim = env.action_space.n  # 2\n",
    "\n",
    "pi = Pi(in_dim, out_dim)  # Policy π_θ for REINFORCE\n",
    "optimizer = optim.Adam(pi.parameters(), lr=0.01)\n",
    "\n",
    "for epi in range(300):\n",
    "    state = env.reset()[0]\n",
    "    for t in range(200):  # CartPole max timestep is 200\n",
    "        action = pi.act(state)\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        pi.rewards.append(reward)\n",
    "        # env.render()\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # Train the policy per episode\n",
    "    loss = train(pi, optimizer)\n",
    "    total_reward = sum(pi.rewards)\n",
    "    solved = total_reward > 195.0\n",
    "\n",
    "    # On-policy: clear memory after training\n",
    "    pi.onpolicy_reset()\n",
    "    print(f'Episode {epi}, loss: {loss}, '\n",
    "            f'total_reward: {total_reward}, solved: {solved}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import RecordVideo\n",
    "from typing import Optional\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    pi: Pi,\n",
    "    env: gym.Env,\n",
    "    n_eval_episodes: int = 10,\n",
    "    video_name: Optional[str] = None,\n",
    ") -> None:\n",
    "    episode_returns, episode_reward = [], 0.0\n",
    "    total_episodes = 0\n",
    "    done = False\n",
    "\n",
    "    # Setup video recorder\n",
    "    video_recorder = None\n",
    "    if video_name is not None and env.render_mode == \"rgb_array\":\n",
    "        os.makedirs(\"../logs/videos/\", exist_ok=True)\n",
    "\n",
    "        # New gym recorder always wants to cut video into episodes,\n",
    "        # set video length big enough but not to inf (will cut into episodes)\n",
    "        env = RecordVideo(env, \"../logs/videos\", step_trigger=lambda _: False, video_length=100_000)\n",
    "        env.start_recording(video_name)\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "    n_actions = int(env.action_space.n)\n",
    "\n",
    "    while total_episodes < n_eval_episodes:\n",
    "\n",
    "        ### YOUR CODE HERE\n",
    "        action = pi.act(obs)\n",
    "\n",
    "\n",
    "        # Send the action to the env\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "        ### END OF YOUR CODE\n",
    "\n",
    "        episode_reward += float(reward)\n",
    "\n",
    "        done = terminated or truncated\n",
    "        if done:\n",
    "            episode_returns.append(episode_reward)\n",
    "            episode_reward = 0.0\n",
    "            total_episodes += 1\n",
    "            obs, _ = env.reset()\n",
    "\n",
    "    if isinstance(env, RecordVideo):\n",
    "        print(f\"Saving video to ../logs/videos/{video_name}\")\n",
    "        env.close()\n",
    "\n",
    "    print(f\"Total reward = {np.mean(episode_returns):.2f} +/- {np.std(episode_returns):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_id = \"CartPole-v1\"\n",
    "\n",
    "eval_env = gym.make(env_id, render_mode=\"rgb_array\")\n",
    "video_name = f\"PG_{env_id}.mp4\"\n",
    "n_eval_episodes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guillaumep/miniconda3/envs/ct-rl-test/lib/python3.10/site-packages/gymnasium/wrappers/rendering.py:283: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/guillaumep/Function-Approximation/notebooks/logs/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving video to ../logs/videos/PG_CartPole-v1.mp4\n",
      "Total reward = 291.33 +/- 18.98\n"
     ]
    }
   ],
   "source": [
    "evaluate(pi, eval_env, n_eval_episodes, video_name=video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_tutorial.notebook_utils import show_videos\n",
    "\n",
    "print(f\"PG agent on {env_id} after 300 iterations:\")\n",
    "show_videos(\"../logs/videos/\", prefix=video_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going Further\n",
    "\n",
    "- Improve the policy gradient algorithm via the natural gradient correction (cf. lecture slides)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct-rl-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
